---
title: Closed Domain Accountability In LLM Products
tags: ["ai","ml","ops"]
date: 2024-4-26
draft: true
---
_grounding your ML product lifecycle in commerical reality_

If you subscribe to the Gartner predictive model for AI impact and adoption (a.k.a the "AI Hype Cycle") we are still far from peak AI expectations:
![Gartner AI Hype Cycle 2023](https://emt.gartnerweb.com/ngw/globalassets/en/newsroom/images/graphs/swe-hc-image.png)

Your Linkedin feed most likely tells the same story, with an endless stream of incredible demos and 

 but a different story as well: one of false claims and frustrated users, automation promises unfulfilled, nightmare customer experiences and AI-powered products gone rogue. What I hear on calls and consults is executives with waining patience. There is still an overwhelming excitement around the potential of large (and small) language model-driven applications, but the reckless abandon with which AI initiatives were undertaken in 2023 seems to be sobering up a bit. For most of us, this is a good thing. If you make a living playing investment valuation shell games then reality is unlikely to be your friend; but if, like most of us, you are a builder who wants to create things that solve problems and actually _work_, then this is a welcome shift in the AI tide. 

So how do we make the transition from squishy intangibles and moving delivery targets to ship _products_ and _features_ that are an unquestionable success?
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTEyMzI1NTYsLTE5MDk5NDA3NDYsMTU4Mj
k2NjQ0Myw0NTI0MzU0MjYsLTE1MjM4OTkxNTcsODU5Njg3MjUz
LC0xMTk3MjAyMzk4XX0=
-->