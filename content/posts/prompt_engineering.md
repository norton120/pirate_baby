---
title: "Prompt Engineering"
subtitle: "some data science is black magic"
date: 2024-1-5
draft: true
---
The world never ceases to be filled with new things, and that is exciting. New things are great, but as they come with a learning curve - not the least of which is the language surrounding them. Like when the first coffee shop opened in the little town where I went to college in the late 90s, and we learned to order “express-o” (which was named that, logically, because it was like coffee but _faster_).  

Such is the case today with words like generative AI, large language models, and of course prompt engineering. These words get tossed into every plan and pitch deck with grand assumptions and promises of near-magic; the ratio of experience to conjecture is painfully low, and the noise from an army of pseudo-knowledgeable content creators looking to cash in on the AI gold isn't helping. 

Take the case of ChatGPT, the most widely recognised LLM on the marketChatGPT is a brilliantly engineered software platform, representing 

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEzMjA3OTE0MzksMTA5OTk2NDYwNl19
-->